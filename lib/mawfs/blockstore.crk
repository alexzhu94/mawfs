# Copyright 2016 Google Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

## Low-level block-store API.

#import crack.exp.fuse fuseMain = main, LockedFilesystem, NodeImpl;
import crack.enc.base64 altEncode, altDecode;
import crack.cont.array Array;
import crack.ascii hex;
import crack.hash Hash;
import crack.hash.sha256 SHA256;
import crack.lang cmp, makeHashVal, AppendBuffer, Buffer, Exception,
    InvalidArgumentError, ManagedBuffer;

import crack.fs Path;
import crack.io FStr, Reader, StringWriter, Writer;

import crack.protobuf readMessageFromString, Field, Message, ProtoWriter;
import crack.crypt.ssl.cipher EVP_aes_256_cbc, DecryptWriter, EncryptWriter;

@import crack.ann interface, impl;
@import crack.protobuf.ann protobuf;

const MAX_NODE_SIZE := 1024 * 1024;

const int
    MODE_DIR = 1,   # A directory.
    MODE_EXE = 2;   # Set the executable flag.

@protobuf {
    ## A filesystem entry.  Nodes can either be directories or blobs.
    ## Directories have a mode of MODE_DIR and their entries all have name
    ## attributes.  Blobs do not have MODE_DIR and their entries all have
    ## sizes, the size being the total size of the contents of the subtree
    ## under that entry.
    message Entry {
        ## The sha256 hash of the encrypted object.
        required bytes hash = 1;

        ## The name of the object (for a directory entry).
        optional string name = 2;

        ## The 32 bit checksum of the original file (calculated by adding
        ## bytes).
        optional int32 org_checksum = 3;

        ## The size of the total contents of the subtree (for a blob entry).
        optional int32 size = 4;
    }

    ## A filesystem node.  MAWFS is agnostic to the difference between files
    ## and directories.  A MAWFS node can contain both named entries and
    ## contents.
    message Node {
        required int32 checksum = 1;
        optional string contents = 2;

        ## 'size' is the size of the data in all children.
        optional int32 size = 4;
        repeated Entry children = 3;

        ## See the MODE_* constants above.  'mode' should be present for all
        ## top-level file nodes and directory nodes.
        optional int32 mode = 5;

# Recursively defined protobufs don't seem to work.  And anyway, we really
# to store the digests of the elements, not the nodes themselves.
#        repeated Node elems = 4;
    }

    ## A commit.  These objects track the history of an entire filesystem.
    message Commit {
        ## The digest of the "parent" commits.  There should generally be one
        ## of these.
        ## The first tree of the filesystem will have no parents.
        ## A "merge" commit (which merges two filesystems) will have more than
        ## one parent.
        repeated bytes parent = 1;

        ## The digest of the root of the filesystem at the point of the commit.
        optional bytes root = 2;
    }
}

String hashFile(Path file) {
    src := file.makeFullReader();
    hasher := SHA256();
    buffer := ManagedBuffer(4096);
    uint64 size;
#    while (rc := src.read(buffer)) {
#        size += rc;
#        cout `\r$size\033[k`;
#        hasher.update(buffer);
#    }
    hasher.update(src.readAll());
    return hasher.digest();
}

## A chunk is the basic unit of data in MAWFS.  We store its content and
## the digest of its encrypted representation.
class Chunk {
    String contents;
    String digest;

    oper init(String contents, String digest) :
        contents = contents,
        digest = digest {
    }
}

# Size of blocks to read and write.
const BLOCK_SIZE := 65536;

class BadDigestError : Exception {
    oper init() {}
    oper init(String message) : Exception(message) {}
}

## Converts a hex representation to binary (e.g. converts "616263" to "abc")
String unhex(String src) {
    if (src.size % 2)
        throw InvalidArgumentError(
            FStr() I`Hex strings must be of even length (got length \
                     $(src.size))`
        );
    byte toNybble(byte b) {
        if (b >= b'0' && b <= b'9')
            return b - b'0';
        else if (b >= b'a' && b <= b'f')
            return b - b'a' + 10;
        else if (b >= b'A' && b <= b'F')
            return b - b'A' + 10;
        else
            throw InvalidArgumentError(
                FStr() `invalid character "$(String(1, b))" in hex string.`
            );
    }
    AppendBuffer result = {64};
    for (int i = 0; i < src.size; i += 2)
        result.append((toNybble(src[i]) << 4) | toNybble(src[i + 1]));
    return String(result, true);
}

class HashAndWrite @impl Writer {

    Hash hasher;
    Writer dst;

    oper init(Hash hasher, Writer dst) :
        hasher = hasher,
        dst = dst {
    }

    void write(Buffer data) {
        hasher.update(data);
        dst.write(data);
    }

    String getDigest() { return hasher.digest(); }
}

## Information on a MAWFS filesystem.
class FSInfo {
    String password;

    oper init(String password) : password = password {}

    ## Reads a "Chunk" from a Reader.  A chunk is the basic unit of data.  The
    ## reader is assumed to be an encrypted stream
    Chunk readChunk(Reader src) {
        hasher := SHA256();
        back := StringWriter();
        decrypter := DecryptWriter(EVP_aes_256_cbc(), password, back);
        while (data := src.read(BLOCK_SIZE)) {
            hasher.update(data);
            decrypter.write(data);
        }

        decrypter.close();

        return Chunk(back.string(), hasher.digest());
    }

    ## Writes and encrypts raw chunk data, returns the digest of the encrypted
    ## data.
    String writeChunk(Writer dst, Buffer data) {
        temp := Buffer(null, 0);
        uint cur;
        HashAndWrite back = {SHA256(), dst};
        encrypter := EncryptWriter(EVP_aes_256_cbc(), password, back);
        while (cur < data.size) {
            temp.size = (data.size - cur > BLOCK_SIZE) ? BLOCK_SIZE :
                                                         data.size - cur;
            temp.buffer = data.buffer + cur;
            encrypter.write(temp);
            cur += temp.size;
        }

        encrypter.close();
        return back.getDigest();
    }

    ## Writes and encrypts a chunk and verifies the digest.  If the digest
    ## doesn't match that of the chunk, throws a BadDigestError.
    void writeChunk(Writer dst, Chunk chunk) {
        if (writeChunk(dst, chunk.contents) != chunk.digest)
            throw BadDigestError();
    }
}

## Interface for a node store.
@interface NodeStore {

    ## Store the node, return its digest.
    @abstract String storeNode(Node node);

    ## Get the node at the given digest, null if it's not currently stored.
    @abstract Node getNode(String digest);

    # Get the root node (null if there is no root).
    @abstract Node getRoot();

    # Get the root digest (null if there is no root).
    @abstract String getRootDigest();

    ## Store the digest of the root node.
    @abstract void storeRoot(String digest);

    ## Returns the digest of the head commit of a given branch.   Returns
    ## null if the branch is not defined.
    @abstract String getHead(String branch);

    ## Sets the digest of the head commit for the branch.
    @abstract void setHead(String branch, String digest);

    ## Write a change to the journal.
    @abstract void writeToJournal(String digest, String change);

    ## Delete the journal for a node.
    @abstract void deleteJournal(String digest);

    ## Return all journal entries for the node with the given digest.
    @abstract Array[String] getJournalEntries(String digest);
}


## Lets you store and load chunks from a persistent back-end.
## This is currently implemented as a thin wrapper around a directory, but it
## should eventually be an interface wrapping any place fine chunks are
## stored.
class ChunkStore @impl NodeStore {

    Path __dir;
    FSInfo __fsInfo;

    oper init(Path dir, FSInfo fsInfo) : __dir = dir, __fsInfo = fsInfo {}

    ## Loads and returns the chunk with the specified digest, returns null if
    ## the chunk doesn't exist in the store.
    ##
    ## Verifies the chunk digest on read, throws BadDigestError if it doesn't
    ## match.
    Chunk load(String digest) {
        path := __dir/hex(digest);
        if (path.exists()) {
            result := __fsInfo.readChunk(path.reader());
            if (result.digest != digest)
                throw BadDigestError(
                    FStr() I`chunk $(hex(digest)) data integrity failure.
                             Actual data digest is $(hex(result.digest))`
                );
            return result;
        } else {
            return null;
        }
    }

    ## Store the chunk.
    ##
    ## Verifies the chunk digest on write, throws BadDigestError if it doesn't
    ## match.
    void store(Chunk chunk) {
        path := __dir/hex(chunk.digest);
        __fsInfo.writeChunk(path.writer(), chunk);
    }

    ## Stores a chunk without a hash.  Returns the digest.
    String store(Buffer data) {
        path := __dir/(FStr() `tempchunk.$(uintz(data))`);
        digest := __fsInfo.writeChunk(path.writer(), data);
        path.moveTo(__dir/hex(digest));
        return digest;
    }

    Node getNode(String digest) {
        chunk := load(digest);
        if (!chunk)
            return null;

        Node node = {};
        readMessageFromString(node, chunk.contents);
        return node;
    }

    ## Stores the node, returns its digest.
    String storeNode(Node node) {
        return store(node.toString());
    }

    ## Returns the root node or null if there is none.
    Node getRoot() {
        rootFile := __dir/'root';
        if (!rootFile.exists())
            return null;
        digest := unhex(rootFile.readAll());
        return getNode(digest);
    }

    String getRootDigest() {
        rootFile := __dir/'root';
        if (!rootFile.exists())
            return null;
        return unhex(rootFile.readAll());
    }

    # Store the current root digest.
    void storeRoot(String digest) {
        (__dir/'root').writeAll(hex(digest));
    }

    void writeToJournal(String digest, String contents) {
#        dst := (__dir/'root').appender();
#        ProtoWriter
    }

    void deleteJournal(String digest) {
    }

    Array[String] getJournalEntries(String digest) {
        return null;
    }

    String getHead(String branch) {
        branchFile := __dir/branch;
        if (!branchFile.exists())
            return null;
        return altDecode(branchFile.readAll());
    }

    void setHead(String branch, String digest) {
        branchFile := __dir/branch;
        if (!branchFile.parent().exists())
            branchFile.parent().makeDirs();
        branchFile.writeAll(altEncode(digest));
    }

    ## Store an entire directory in the blockstore.  Returns its digest.
#    String storeDir(Path root) {
#        files := Array[Entry]![];
#        for (file :in root.children()) {
#            if (file.isDir()) {
#                storeDir(file);
#            } else {
#                files.append(Entry
}
